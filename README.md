# ğŸ¤– n8n + Ollama Local AI Chatbot

This project demonstrates how to run **n8n** locally and connect it with **Ollama** to use **local LLM models** (like TinyLlama / Llama3) for AI chat workflows.

No cloud. No API keys. Fully local ğŸš€

---

## ğŸ§© Architecture Overview



User â†’ n8n Workflow â†’ Ollama (Local LLM)


- **n8n** â†’ Automation & workflow engine  
- **Ollama** â†’ Runs AI models locally  
- **HTTP / AI Agent Node** â†’ Connects n8n with Ollama  

---

## âœ… Prerequisites

- Windows 10 / 11  
- Node.js (v18 or later)  
- npm  
- Internet (only for first-time installs)

---

## ğŸ”¹ Step 1: Install Ollama (Windows)

Download and install Ollama:

ğŸ‘‰ https://ollama.com/download/windows

Verify installation:
```bash
ollama --version


Pull a model (example: TinyLlama):

ollama pull tinyllama


Test model:

ollama run tinyllama


Ollama runs on:

http://localhost:11434

ğŸ”¹ Step 2: Install n8n Locally

Install n8n globally using npm:

npm install -g n8n


Verify installation:

n8n --version


Start n8n:

n8n


Open n8n in browser:

http://localhost:5678

ğŸ”¹ Step 3: Create n8n Workflow

Open n8n UI

Click Create Workflow

Add Chat Trigger (or Webhook for API-based chat)

Add AI Agent node

Add Ollama Chat Model

ğŸ”¹ Step 4: Configure Ollama Chat Model
Connection Settings

Base URL:

http://localhost:11434


(Use http://host.docker.internal:11434 if n8n runs in Docker)

Model Name:

tinyllama


or

llama3

ğŸ”¹ Step 5: Connect AI Agent

Attach Chat Trigger â†’ AI Agent

Select Ollama Chat Model inside AI Agent

Set system prompt (optional):

You are a helpful AI assistant.

ğŸ”¹ Step 6: Test the Workflow

Click Chat

Ask a question:

Explain n8n like I am 10 years old


You should receive a response from the local AI ğŸ‰


Check Ollama is running:

ollama list


Verify port:

11434

ğŸ§  Supported Models

tinyllama

llama3

mistral

codellama

phi

(Any model supported by Ollama)

ğŸš€ Use Cases

Local ChatGPT-style chatbot

AI-powered automation

Internal company AI assistant

Privacy-first GenAI workflows

RAG pipelines (future)

ğŸ“Œ Status

âœ… Ollama installed
âœ… n8n installed
âœ… Workflow created
âœ… AI Agent connected
ğŸš§ Advanced features in progress (RAG, memory, tools)

ğŸ‘¨â€ğŸ’» Author

Rohit Sharma
GenAI | Automation | Backend
